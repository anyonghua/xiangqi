# Work Flow
（English version comes later）

---
# 基本工作流程

人类在下棋的过程一样，面对一个局面时候要选择下一手棋，需要往后面看几手棋。
这个过程仔细分析的话，有这么几个步骤：
- 凭借经验或直觉先列出一些下一步走法
- 自己模拟一下走法，评估一下局势
- 对于明朗的局势，分析结束；对于不明朗的局势，继续再往下走一步，重复前面的过程。

计算机的算法和这个是一致的。
- 列出走法的部分叫**走法生成**，`MoveGenerator`。
- 评估局势的部分叫**估值函数**，`Evaluator`。
- 控制着流程的部分，控制着产生走法，模拟走棋，评估局势，是否进一步分析等的是**搜索引擎**，`SearchEngine`。

## 走法生成
演示用的`SimplaMoveGenerator`是很容易想到一个最简单的算法。那就是列出全部可能的走法，而这个过程不需要去直接评估分析好坏，筛选走法。只是这样一来，后面分析的任务会有点大。一些没必要的走法，可能也要分析一遍。一些胜率相近的走法，其实随便走一个都行，但还是都要分析一遍。

人类棋手的优势在于棋感，可以率先在这一步过滤掉看上去不怎么好的走法。而且也可以根据积累下来的知识和经验，根据棋谱快速筛选出有必要深入考虑的走法。其实，这相当于自带一个非常快速的评估功能。用逻辑语言去描述的话，很难讲清楚怎么筛选走法。但是从成千上万对局里面进行统计的话，可能会发现难以用公式表达的规律。人工智能就是这么做的。这也是在模仿人类。人类棋手的棋感也是对局练出来的，棋谱也是人类对局保留积累下来的。

## 估值函数
这个是评价一个局面对自己的有利程度的。只有准确地判断是否对自己有利才能从众多可能的走法中筛选出最佳的方案。

为什么需要评估局面呢？根本原因还是棋局的状态太多了。这导致棋手或者计算机无法进行深层次的推算。如果有足够计算力的话，每一个局面推算到最后都是胜、负或平局这三者之一。这都是明确的结果。但如果计算力不够，那就只能在浅层次上评估局势是否有利的。

演示用的`SimpleEvalutor`是一个简单的估值函数。它主要考虑以下几方面因素来评估。
- 棋子本身的价值。一般由其固有的攻击力决定的。
- 棋子的灵活性。这个取决于棋子的规则，以及棋盘上的位置。
- 棋子的价值变化。这个主要是棋子因为规则，固有的攻击力发生变化。比如中国象棋中，兵/卒过河之后，攻击力增加。但到达底线之后，攻击力又减小了。
以上三者是局势有利度的基本值。在此之上。
- 棋子被攻击的状态，有利度减少。
- 棋子被攻击的状态，但同时又处于被保护状态，则有利度稍稍减少（相对于仅仅被攻击的状况程度要小得多）。
- 棋子同时被多个棋子攻击的时候，攻击越多，有利度越小。这个保证兑子的时候能判断是否有利。
- 棋子仅仅被保护，不受攻击。有利度稍微增加。这表示防守布局成功。

双方各自计算有利度之后，作差即可判断局势倾向于哪一边。

在`SimpleEvalutor`中，表示局势的值的分布为：
- -20000 已经失败。比如王/将已经丢了。
- -19999 一步之后必败。比如被将死的时候。
- -19998 两步之后必败
- ……
- -19900 100步之后必败
- -19899 近乎必败
- ……
- 0 势均力敌
- ……
- 19899 近乎必胜
- 19900 100步后必胜
- ……
- 19998 两步后必胜
- 19999 一步后必胜
- 20000 已经胜利。

## 搜索引擎
假设估值函数在评价局面的时候，总是用先手有利度减去后手有利度。那么数值越大，对先手越有利；数值越小，对后手越有利。因此，在推算每一步的时候，自己（假定是先手）总是要让局面的值最大，而对方总是让局面的值最小。
### Minimax(极小极大算法)
把轮番走棋的过程画成一个树状图。显而易见，偶数（0，2，4，……）层是属于自己一方的，要从子树中取极大值；奇数（1，3，5，……）层是对方走棋，对方足够聪明，一定取子树种的极小值。


### Negamax(负极大值算法)
利用等式`min(a,b)=-max(-a,-b)`，可以将Minimax的算法变成每一层都取负极大值。

### AlphaBeta(αβ搜索算法)
进一步优化，在搜索过程中维持一个上下界`[α,β]`进行剪枝。这类似人类棋手在思考时，如果发现某一个走法一定不如前面发现的走法，那么就放弃继续深入推算。
一般来说，开始时从`[-inf, inf]`开始搜索。

### Fail-soft AlphaBeta（Fail-soft的αβ搜索算法）
稍微改进版的αβ搜索算法。效率上并不会有改善，但是比起Fail-hard的αβ搜索算法能提供更多信息。
假设不是从`[-inf, inf]`开始搜索，而是从某个区间`[α,β]`开始搜索。那么最终结果可能三种情况：最佳走法的估值`s`
- `s < α`，即fail low
- `α <= s <= β`，即计算得到准确值
- `β < s`，即fail high

前述的Alphabeta是fail-hard的，也就是仅当`α <= s <= β`时能返回准确值，而fail low/high时均不能得到任何信息。相对地，fail-soft的αβ搜索算法在fail-low时给出`s`的上限，在fail-high时给出`s`的下限。这就为窄窗口多次搜索提供了基础。

### Aspiration Search(渴望搜索)
先猜一个值`X`，然后在`X`附近用窄窗口`[X-WIN, X+WIN]`搜索。当然，fail high的话，就在得到的下限和+inf之间搜一次；fail low的话，就在-inf和得到的上限之间搜一次。显然，如果`X`比较接近目标值的话，大部分状况下窄窗搜索就能完成任务了。

为了找到比较准确的`X`，一般是先浅层地在`[-inf, +inf]`搜一次得出。不过，这样的问题就是评估函数的敏感性决定效率。如果搜索树两层之间，评估函数的值会发生巨大变化，那么浅层粗略搜索得出的`X`可能和深层精细搜索的目标值相差较大。

### Principal Variation Search(极小窗口搜索)

### NegaScout

### 优化手段

#### Transposition Table(置换表)

#### History Heuristic(历史启发)

#### Iterative Deepening(迭代深化)

### MTD(f)
